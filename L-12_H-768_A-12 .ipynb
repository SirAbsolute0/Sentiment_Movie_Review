{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884bd454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import neccessary modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "from sklearn import metrics\n",
    "\n",
    "tf.random.set_seed(1209)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac29699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test data into pandas df\n",
    "train_df = np.load('train/data.npz')\n",
    "test_df = np.load('test/test.npz')\n",
    "\n",
    "train = pd.DataFrame([train_df['a'], train_df['b']]).T\n",
    "train_data, train_vald_data = train_test_split(train, test_size = 0.35, shuffle = True, random_state = 1209)\n",
    "train_data.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "train_vald_data.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "\n",
    "test = pd.DataFrame([test_df['a'], test_df['b']]).T\n",
    "test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1517505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to convert words into bytes for Bert models\n",
    "#Code provided by Steve\n",
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, \n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, \n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "  \n",
    "  return train_InputExamples, validation_InputExamples\n",
    "  \n",
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.float64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84dd1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'DATA_COLUMN'\n",
    "LABEL_COLUMN = 'LABEL_COLUMN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3316192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  95306496  \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95,308,034\n",
      "Trainable params: 95,308,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Download the Bert models\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-10_H-768_A-12\", from_pt=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google/bert_uncased_L-10_H-768_A-12\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8cf1cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Create train_data and validation_data set\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train_data, train_vald_data, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "training_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "training_data = training_data.shuffle(100, seed = 1209).batch(16).repeat(2)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4809638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2032/2032 [==============================] - 482s 231ms/step - loss: 0.2957 - accuracy: 0.8749 - val_loss: 0.3482 - val_accuracy: 0.8675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a3b01d1f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile and run model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=5e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(training_data, epochs=1, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507f7b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Create test sets\n",
    "test_InputExamples, test_validation_InputExamples = convert_data_to_examples(test, train_vald_data, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "testing_data = convert_examples_to_tf_dataset(list(test_InputExamples), tokenizer)\n",
    "testing_data = testing_data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff67f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phuong Hoang Dinh\\AppData\\Local\\Temp\\ipykernel_18780\\3515725654.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  actual_lables = test_df['b'].astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "#Predict results from testing data\n",
    "pred_labels = model.predict(testing_data)\n",
    "pred_results = np.argmax(pred_labels.logits, axis=1)\n",
    "actual_lables = test_df['b'].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1ee3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.87356\n",
      "Precision score: 0.8530812854442344\n",
      "Recall score: 0.90256\n",
      "F1-score: 0.8771234207968902\n"
     ]
    }
   ],
   "source": [
    "#Get the scure and confusion matrix\n",
    "confusion = metrics.confusion_matrix(actual_lables, pred_results)\n",
    "acc = metrics.accuracy_score(actual_lables, pred_results)\n",
    "precision = metrics.precision_score(actual_lables, pred_results)\n",
    "recall = metrics.recall_score(actual_lables, pred_results)\n",
    "F1 = metrics.f1_score(actual_lables, pred_results)\n",
    "print(\"Accuracy score: \" + str(acc))\n",
    "print(\"Precision score: \"+ str(precision))\n",
    "print(\"Recall score: \" + str(recall))\n",
    "print(\"F1-score: \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61d56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
